import random
import numpy as np
from deap import base, creator, tools
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import recall_score, accuracy_score
from sklearn.model_selection import cross_val_score  # Ajout pour la validation crois√©e
from sklearn.metrics import make_scorer  # Ajout pour cr√©er un scorer personnalis√©
import matplotlib.pyplot as plt
import time


("""Quoi ? Cette fonction calcule la moyenne des rappels (recall) des classes 0 et 1. Le rappel est la proportion de vrais positifs d√©tect√©s pour une classe (ex. TP / (TP + FN)).
Pourquoi ? C‚Äôest notre crit√®re d‚Äôoptimisation (la "fitness"). On veut que le mod√®le soit bon pour d√©tecter √† la fois les 0 et les 1, pas seulement une classe.
Exemple :
Si y_true = [0, 1, 0, 1] et y_pred = [0, 1, 1, 1] :
Rappel classe 1 : 2/2 = 1.0 (tous les 1 sont d√©tect√©s).
Rappel classe 0 : 1/2 = 0.5 (un seul 0 d√©tect√© sur deux).
custom_precision = (1.0 + 0.5) / 2 = 0.75.""")
def custom_precision(y_true, y_pred):
    recall_class_1 = recall_score(y_true, y_pred, pos_label=1)  # Rappel pour la classe 1
    recall_class_0 = recall_score(y_true, y_pred, pos_label=0)  # Rappel pour la classe 0
    return (recall_class_1 + recall_class_0) / 2  # Moyenne des deux


# üìå Chargement des donn√©es pr√©d√©finies depuis les fichiers Excel
data_train_path = "C:/Users/malle/OneDrive/Bureau/Algo_optimisation_hyperparam/als_train_t3.xlsx"
data_test_path = "C:/Users/malle/OneDrive/Bureau/Algo_optimisation_hyperparam/als_test_t3.xlsx"
df_train = pd.read_excel(data_train_path)  # Donn√©es d‚Äôentra√Ænement
df_test = pd.read_excel(data_test_path)  # Donn√©es de test

# üìå S√©paration des features et labels
# Exemple : X_train contient toutes les colonnes sauf "Survived", y_train contient "Survived".
X_train = df_train.drop(columns=['Survived'])  # Features d‚Äôentra√Ænement
y_train = df_train['Survived']  # Labels d‚Äôentra√Ænement
X_test = df_test.drop(columns=['Survived'])  # Features de test
y_test = df_test['Survived']  # Labels de test

# üìå D√©finition des plages d‚Äôhyperparam√®tres
# Ces plages limitent les valeurs possibles pour chaque hyperparam√®tre.
param_ranges = {
    'n_estimators': (10, 500),  # Nombre d‚Äôarbres dans la for√™t
    'max_depth': (3, 50),  # Profondeur maximale des arbres
    'min_samples_split': (2, 10),  # Minimum d‚Äô√©chantillons pour diviser un n≈ìud
    'min_samples_leaf': (1, 5),  # Minimum d‚Äô√©chantillons dans une feuille
    'max_features': ["sqrt", "log2"],  # M√©thode pour choisir le nombre de features
    'criterion': ["gini", "entropy"]  # Crit√®re de division des n≈ìuds
}


("""Quoi ? On d√©finit deux classes :
FitnessMax : une classe pour repr√©senter la fitness (le score √† maximiser), ici custom_precision.
Individual : une classe pour repr√©senter un individu, qui est une liste d‚Äôhyperparam√®tres avec une fitness associ√©e.
Pourquoi ? DEAP ne fournit pas de structure pr√©d√©finie pour les individus. creator permet de cr√©er des conteneurs
 personnalis√©s. weights=(1.0,) indique qu‚Äôon maximise un seul objectif (contrairement √† une optimisation multi-objectifs).
Exemple : Un individu pourrait √™tre [150, 20, 4, 3, "sqrt", "gini"], avec une fitness comme (0.85,).""")
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)

# üìå Initialisation de la bo√Æte √† outils (toolbox)
toolbox = base.Toolbox()

(""" Quoi ? On configure la toolbox pour g√©n√©rer des individus et une population :
G√©n√©rateurs : Chaque attr_ g√©n√®re une valeur al√©atoire (ex. attr_n_estimators peut donner 200).
Individu : initCycle combine les g√©n√©rateurs pour cr√©er une liste de 6 hyperparam√®tres.
Population : initRepeat cr√©e une liste d‚Äôindividus.
Pourquoi ? La toolbox est le c≈ìur de l‚ÄôAG dans DEAP. Elle organise les outils pour cr√©er et manipuler la population.
Exemple :
Appel de toolbox.individual() : [150, 20, 4, 3, "sqrt", "gini"].
Appel de toolbox.population(n=3) : [[150, 20, 4, 3, "sqrt", "gini"], [200, 10, 5, 2, "log2", "entropy"], 
[100, 15, 3, 1, "sqrt", "entropy"]].""")
toolbox.register("attr_n_estimators", random.randint, *param_ranges['n_estimators'])
toolbox.register("attr_max_depth", random.randint, *param_ranges['max_depth'])
toolbox.register("attr_min_samples_split", random.randint, *param_ranges['min_samples_split'])
toolbox.register("attr_min_samples_leaf", random.randint, *param_ranges['min_samples_leaf'])
toolbox.register("attr_max_features", random.choice, param_ranges['max_features'])
toolbox.register("attr_criterion", random.choice, param_ranges['criterion'])
toolbox.register("individual", tools.initCycle, creator.Individual,
                 (toolbox.attr_n_estimators, toolbox.attr_max_depth, toolbox.attr_min_samples_split,
                  toolbox.attr_min_samples_leaf, toolbox.attr_max_features, toolbox.attr_criterion),
                 n=1)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)


("""Quoi ? Cette fonction entra√Æne un mod√®le avec les hyperparam√®tres d‚Äôun individu et calcule son score custom_precision.
Pourquoi ? C‚Äôest la "fitness" qui indique √† l‚ÄôAG si un individu est bon ou non. Plus le score est √©lev√©, meilleur est l‚Äôindividu.
Exemple : Pour [150, 20, 4, 3, "sqrt", "gini"], si le mod√®le obtient un recall de 0.9 pour la classe 1 et 0.8 pour la classe 0,
 alors score = 0.85, retourn√© comme (0.85,).""")
def evaluate(individual):
    model = RandomForestClassifier(
        n_estimators=individual[0],  # Ex. 150
        max_depth=individual[1],  # Ex. 20
        min_samples_split=individual[2],  # Ex. 4
        min_samples_leaf=individual[3],  # Ex. 3
        max_features=individual[4],  # Ex. "sqrt"
        criterion=individual[5],  # Ex. "gini"
        random_state=42
    )
    # Utilisation de la validation crois√©e √† 5 plis avec custom_precision
    custom_scorer = make_scorer(custom_precision)
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=custom_scorer)
    score = np.mean(scores)  # Moyenne des scores sur les 5 plis
    return score,  # Tuple requis par DEAP


toolbox.register("evaluate", evaluate)


("""Quoi ? On d√©finit trois op√©rateurs :
Croisement (mate) : cxTwoPoint √©change des segments entre deux individus.
Mutation : Modifie al√©atoirement un hyperparam√®tre.
S√©lection : selTournament choisit les meilleurs individus par tournoi.
Pourquoi ? Ces op√©rateurs simulent l‚Äô√©volution :
Croisement m√©lange les "bons g√®nes".
Mutation introduit de la diversit√©.
S√©lection garde les meilleurs.
Exemple :
Croisement : [150, 20, 4, 3, "sqrt", "gini"] et [200, 10, 5, 2, "log2", "entropy"] ‚Üí [150, 10, 5, 2, "log2", "entropy"].
Mutation : [150, 20, 4, 3, "sqrt", "gini"] ‚Üí [150, 25, 4, 3, "sqrt", "gini"].
S√©lection : Parmi [0.85], [0.78], [0.90], le tournoi choisit [0.90].""")
toolbox.register("mate", tools.cxTwoPoint)
def mutate(individual):
    ("""Exemple :
individual = [150, 20, 4, 3, "sqrt", "gini"], index = 2 (min_samples_split).
param_name = "min_samples_split", plage = (2, 10).
random.randint(2, 10) retourne 7.
R√©sultat : individual = [150, 20, 7, 3, "sqrt", "gini"]. """)
    index = random.randint(0, len(individual) - 1)  # Choisir un param√®tre √† muter
    if index < 4:  # Param√®tres num√©riques
        param_name = list(param_ranges.keys())[index]
        individual[index] = random.randint(*param_ranges[param_name])
    else:  # Param√®tres cat√©goriques
        ("""individual = [150, 20, 4, 3, "sqrt", "gini"], index = 5 (criterion).
param_name = "criterion", options = ["gini", "entropy"].
random.choice(["gini", "entropy"]) retourne "entropy".
R√©sultat : individual = [150, 20, 4, 3, "sqrt", "entropy"]. """)
        param_name = list(param_ranges.keys())[index]
        individual[index] = random.choice(param_ranges[param_name])
    return individual,


toolbox.register("mutate", mutate)
toolbox.register("select", tools.selTournament, tournsize=3)  # S√©lection par tournoi (3 candidats)


# üìå Fonction principale pour ex√©cuter l‚Äôalgorithme g√©n√©tique
def main():
    # üìå Param√®tres de l‚Äôalgorithme
    POP_SIZE = 100   # Taille de la population (ex. 50 individus)
    NGEN = 20  # Nombre de g√©n√©rations
    CXPB = 0.7  # Probabilit√© de croisement (50%)
    MUTPB = 0.4
    # Probabilit√© de mutation (20%)

    # üìå Cr√©ation de la population initiale
    pop = toolbox.population(n=POP_SIZE)
    print(f"\nüîç Population initiale cr√©√©e avec {POP_SIZE} individus.")

    # üìå Liste pour suivre l‚Äô√©volution de l‚Äôaccuracy
    best_custom_precisions = []  # Modifi√© pour suivre custom_precision

    # üìå D√©marrer le chronom√®tre
    start_time = time.time()

    # üìå √âvaluation initiale de la population
    fitnesses = list(map(toolbox.evaluate, pop))
    for ind, fit in zip(pop, fitnesses):
        ind.fitness.values = fit  # Assigner la fitness √† chaque individu

    print("\nüîç D√©but de l'optimisation g√©n√©tique...")

    ("""Quoi ? La boucle it√®re NGEN fois (ex. 20 g√©n√©rations). 
    √Ä chaque it√©ration, on affiche le num√©ro de la g√©n√©ration (ex. "G√©n√©ration 1", "G√©n√©ration 2", etc.).""")
    for g in range(NGEN):
        print(f"\n-- G√©n√©ration {g + 1} --")
        ("""toolbox.select(pop, len(pop)) : Utilise la m√©thode selTournament (enregistr√©e dans la toolbox) pour 
            s√©lectionner len(pop) individus (ex. 50) parmi la population actuelle pop. Le "tournoi" choisit les meilleurs
             selon leur fitness (custom_precision).
        list(map(toolbox.clone, offspring)) : Cr√©e une copie profonde de chaque individu s√©lectionn√©.
        Pourquoi ?
        S√©lection : On garde les individus les plus performants pour "reproduire" leurs caract√©ristiques, comme dans
        la s√©lection naturelle.
        Clonage : On clone pour √©viter que les modifications (croisement/mutation) affectent la population originale directement.
        Exemple :
        pop = [[150, 20, 4, 3, "sqrt", "gini"], [200, 10, 5, 2, "log2", "entropy"], ...] (50 individus).
        Fitness : [0.85, 0.82, ...].
        Apr√®s s√©lection : offspring = [[150, 20, 4, 3, "sqrt", "gini"], [200, 10, 5, 2, "log2", "entropy"], ...]
         (les meilleurs sont choisis).
        Clonage : offspring est une copie ind√©pendante.""")
        offspring = toolbox.select(pop, len(pop))
        offspring = list(map(toolbox.clone, offspring))  # Clonage pour √©viter les modifications directes

        ("""Exemple :
child1 = [150, 20, 4, 3, "sqrt", "gini"], child2 = [200, 10, 5, 2, "log2", "entropy"].
Si random.random() = 0.3 < 0.5, on croise.
Points de coupe : entre positions 1 et 2, et 4 et 5.
R√©sultat :
child1 = [150, 10, 5, 2, "sqrt", "gini"]
child2 = [200, 20, 4, 3, "log2", "entropy"]
Fitness supprim√©e car les enfants sont nouveaux.""")
        for child1, child2 in zip(offspring[::2], offspring[1::2]):
            if random.random() < CXPB:
                toolbox.mate(child1, child2)
                del child1.fitness.values
                del child2.fitness.values

        # üìå Mutation
        ("""Exemple :
mutant = [150, 20, 4, 3, "sqrt", "gini"].
Si random.random() = 0.1 < 0.2, on mute.
Mutation sur index = 1 (max_depth) : nouvelle valeur ‚Üí 25.
R√©sultat : mutant = [150, 25, 4, 3, "sqrt", "gini"].""")
        for mutant in offspring:
            if random.random() < MUTPB:
                toolbox.mutate(mutant)
                del mutant.fitness.values

        # üìå √âvaluation des individus modifi√©s
        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
        fitnesses = map(toolbox.evaluate, invalid_ind)
        for ind, fit in zip(invalid_ind, fitnesses):
            ind.fitness.values = fit
        ("""Quoi ? La population actuelle pop est remplac√©e par la nouvelle g√©n√©ration offspring.
        Pourquoi ? C‚Äôest la fin d‚Äôune g√©n√©ration : les nouveaux individus (s√©lectionn√©s, crois√©s, mut√©s)
         deviennent la base de la g√©n√©ration suivante.
        Exemple : Si offspring contient 50 individus am√©lior√©s, pop est mise √† jour avec ces 50 nouveaux.""")
        # üìå Remplacement de la population
        pop[:] = offspring

        # üìå Statistiques et affichage du meilleur individu
        fits = [ind.fitness.values[0] for ind in pop]
        best_ind = tools.selBest(pop, k=1)[0]  # Meilleur individu de la g√©n√©ration

        # Calcul de la custom_precision pour le meilleur individu (via fitness)
        custom_precision_score = best_ind.fitness.values[0]  # R√©cup√©r√© directement de la fitness (CV)
        best_custom_precisions.append(custom_precision_score)

        # Calcul de l‚Äôaccuracy pour le meilleur individu (inchang√© pour l‚Äôaffichage)
        model = RandomForestClassifier(
            n_estimators=best_ind[0], max_depth=best_ind[1], min_samples_split=best_ind[2],
            min_samples_leaf=best_ind[3], max_features=best_ind[4], criterion=best_ind[5],
            random_state=42
        )
        model.fit(X_train, y_train)
        y_pred_train = model.predict(X_train)
        accuracy = accuracy_score(y_train, y_pred_train)

        # üìå Affichage d√©taill√©
        print(f"  Meilleurs hyperparam√®tres : {best_ind}")
        print(f"  Score personnalis√© (fitness) : {best_ind.fitness.values[0]:.4f}")
        print(f"  Accuracy (train) : {accuracy:.4f}")
        print(f"  Moyenne des scores : {sum(fits) / len(pop):.4f}")
        print(f"  Minimum : {min(fits):.4f}")
        print(f"  Maximum : {max(fits):.4f}")

    # üìå Calcul et affichage du temps d‚Äôex√©cution
    elapsed_time = time.time() - start_time
    print(f"\n‚è±Ô∏è Temps d'ex√©cution de l'algorithme g√©n√©tique : {elapsed_time / 60:.2f} minutes")

    # üìå R√©sultat final : meilleur individu
    best_individual = tools.selBest(pop, k=1)[0]
    print("\n‚úÖ Meilleurs hyperparam√®tres finaux :", best_individual)

    # üìå Entra√Ænement du mod√®le final
    best_model = RandomForestClassifier(
        n_estimators=best_individual[0], max_depth=best_individual[1],
        min_samples_split=best_individual[2], min_samples_leaf=best_individual[3],
        max_features=best_individual[4], criterion=best_individual[5],
        random_state=42
    )
    best_model.fit(X_train, y_train)

    # üìå √âvaluation sur train et test
    y_pred_train = best_model.predict(X_train)
    y_pred_test = best_model.predict(X_test)
    custom_score_train = custom_precision(y_train, y_pred_train)
    custom_score_test = custom_precision(y_test, y_pred_test)
    accuracy_train = accuracy_score(y_train, y_pred_train)
    accuracy_test = accuracy_score(y_test, y_pred_test)

    # üìå Affichage des r√©sultats finaux
    print("\nüìä R√©sultats finaux :")
    print(f"üîπ Score personnalis√© (train) : {custom_score_train:.4f}")
    print(f"üîπ Accuracy (train) : {accuracy_train:.4f}")
    print(f"üîπ Score personnalis√© (test) : {custom_score_test:.4f}")
    print(f"üîπ Accuracy (test) : {accuracy_test:.4f}")

    # üìå Graphique de l‚Äô√©volution de la custom_precision
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, NGEN + 1), best_custom_precisions, marker='o', color='blue', linestyle='-', label='Custom Precision (validation crois√©e)')
    plt.xlabel('G√©n√©ration')
    plt.ylabel('Custom Precision Moyenne (validation)')
    plt.title('√âvolution de la Custom Precision au fil des g√©n√©rations (Algorithme G√©n√©tique)')
    plt.grid(True)
    plt.legend()
    plt.show()

    return best_individual


# üìå Lancement de l‚Äôalgorithme
if __name__ == "__main__":
    best_solution = main()
    print("\nüéØ Optimisation termin√©e avec succ√®s !")